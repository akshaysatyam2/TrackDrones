{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8292342,"sourceType":"datasetVersion","datasetId":4926150}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Simple CNN Model for classification","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntraining_set = train_datagen.flow_from_directory('/kaggle/input/drone-and-not-drone/train',\n                                                 target_size = (224, 224),\n                                                 batch_size = 32,\n                                                 class_mode = 'binary')\n\ncnn = tf.keras.models.Sequential()\n\ncnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[224, 224, 3]))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n\ncnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n\ncnn.add(tf.keras.layers.Flatten())\n\ncnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n\ncnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n\ncnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\ncnn.fit(training_set, epochs = 25)","metadata":{"execution":{"iopub.status.busy":"2024-05-03T11:38:53.483874Z","iopub.execute_input":"2024-05-03T11:38:53.484714Z","iopub.status.idle":"2024-05-03T11:52:12.009388Z","shell.execute_reply.started":"2024-05-03T11:38:53.484679Z","shell.execute_reply":"2024-05-03T11:52:12.007879Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found 127 images belonging to 2 classes.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/25\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:54\u001b[0m 38s/step - accuracy: 0.4688 - loss: 0.7345","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1714736390.995877     115 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1714736391.012791     115 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.4534 - loss: 8.5504 \nEpoch 2/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 40ms/step - accuracy: 0.5807 - loss: 0.6728\nEpoch 3/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 41ms/step - accuracy: 0.5902 - loss: 0.6493\nEpoch 4/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 41ms/step - accuracy: 0.5928 - loss: 0.6477\nEpoch 5/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.6450 - loss: 0.6095\nEpoch 6/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 40ms/step - accuracy: 0.7804 - loss: 0.5557\nEpoch 7/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 41ms/step - accuracy: 0.6983 - loss: 0.5590\nEpoch 8/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 41ms/step - accuracy: 0.7298 - loss: 0.5149\nEpoch 9/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 40ms/step - accuracy: 0.7175 - loss: 0.5080\nEpoch 11/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 41ms/step - accuracy: 0.8365 - loss: 0.4101\nEpoch 12/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 40ms/step - accuracy: 0.7857 - loss: 0.4018\nEpoch 13/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 44ms/step - accuracy: 0.7854 - loss: 0.4062\nEpoch 14/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.8188 - loss: 0.4063\nEpoch 15/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 41ms/step - accuracy: 0.8318 - loss: 0.3653\nEpoch 16/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 40ms/step - accuracy: 0.8293 - loss: 0.3653\nEpoch 17/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 40ms/step - accuracy: 0.8547 - loss: 0.3375\nEpoch 18/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.8934 - loss: 0.2992\nEpoch 19/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 40ms/step - accuracy: 0.8869 - loss: 0.2648\nEpoch 20/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 42ms/step - accuracy: 0.9279 - loss: 0.2192\nEpoch 24/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 41ms/step - accuracy: 0.9289 - loss: 0.2142\nEpoch 25/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 39ms/step - accuracy: 0.9132 - loss: 0.1779\n{'Drone': 0, 'Not Drone': 1}\nFound 11 images belonging to 1 classes.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 48\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(training_set\u001b[38;5;241m.\u001b[39mclass_indices)\n\u001b[1;32m     42\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/drone-and-not-drone/val\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     44\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m),\n\u001b[1;32m     45\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     46\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(test_generator)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import os, numpy as np\nfrom tensorflow.keras.preprocessing import image\n\ntest_folder = \"/kaggle/input/drone-and-not-drone/val/Drone/\"\n\nprint(training_set.class_indices)\n\ntest_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/drone-and-not-drone/val',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='binary')\n\nloss, accuracy = cnn.evaluate(test_generator)\nprint(f'Test accuracy: {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2024-05-03T12:14:36.928155Z","iopub.execute_input":"2024-05-03T12:14:36.928522Z","iopub.status.idle":"2024-05-03T12:14:40.948760Z","shell.execute_reply.started":"2024-05-03T12:14:36.928486Z","shell.execute_reply":"2024-05-03T12:14:40.947895Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"{'Drone': 0, 'Not Drone': 1}\nFound 11 images belonging to 1 classes.\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.7273 - loss: 1.1845\nTest accuracy: 0.7272727489471436\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Fine tuning ResNet50 Model for classification","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nresnet_base = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nfor layer in resnet_base.layers:\n    layer.trainable = False\n\nx = GlobalAveragePooling2D()(resnet_base.output)\nx = Dense(128, activation='relu')(x)\npredictions = Dense(1, activation='sigmoid')(x)\n\nmodel = Model(inputs=resnet_base.input, outputs=predictions)\n\nmodel.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n\ntrain_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/drone-and-not-drone/train',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='binary')\n\nhistory = model.fit(train_generator, epochs=25)\n\ntest_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/drone-and-not-drone/val',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='binary')\n\nloss, accuracy = model.evaluate(test_generator)\nprint(f'Test accuracy: {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2024-05-03T12:15:05.236429Z","iopub.execute_input":"2024-05-03T12:15:05.236834Z","iopub.status.idle":"2024-05-03T12:28:41.905915Z","shell.execute_reply.started":"2024-05-03T12:15:05.236805Z","shell.execute_reply":"2024-05-03T12:28:41.904928Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nFound 127 images belonging to 2 classes.\nEpoch 1/25\n\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:24\u001b[0m 48s/step - accuracy: 0.4688 - loss: 0.7015","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1714738571.348101     113 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.4922 - loss: 0.7399 ","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1714738580.261883     116 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 3s/step - accuracy: 0.4906 - loss: 0.7408\nEpoch 2/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 94ms/step - accuracy: 0.5184 - loss: 0.7010\nEpoch 3/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 96ms/step - accuracy: 0.5676 - loss: 0.6917\nEpoch 4/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 87ms/step - accuracy: 0.6376 - loss: 0.6724\nEpoch 5/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 87ms/step - accuracy: 0.6482 - loss: 0.6670\nEpoch 6/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 92ms/step - accuracy: 0.6083 - loss: 0.6776\nEpoch 7/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 87ms/step - accuracy: 0.5487 - loss: 0.6702\nEpoch 8/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 88ms/step - accuracy: 0.4882 - loss: 0.6760\nEpoch 9/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 86ms/step - accuracy: 0.5684 - loss: 0.6598\nEpoch 10/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 97ms/step - accuracy: 0.5236 - loss: 0.6716\nEpoch 11/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 95ms/step - accuracy: 0.7192 - loss: 0.6459\nEpoch 12/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - accuracy: 0.5944 - loss: 0.6367\nEpoch 13/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 94ms/step - accuracy: 0.7087 - loss: 0.6379\nEpoch 14/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 88ms/step - accuracy: 0.6869 - loss: 0.6131\nEpoch 15/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 92ms/step - accuracy: 0.6096 - loss: 0.6225\nEpoch 16/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 91ms/step - accuracy: 0.7707 - loss: 0.6183\nEpoch 17/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 88ms/step - accuracy: 0.6597 - loss: 0.6224\nEpoch 18/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 89ms/step - accuracy: 0.6891 - loss: 0.6047\nEpoch 19/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 91ms/step - accuracy: 0.6901 - loss: 0.6013\nEpoch 20/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 97ms/step - accuracy: 0.6542 - loss: 0.6068\nEpoch 21/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 95ms/step - accuracy: 0.6806 - loss: 0.5954\nEpoch 22/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.7177 - loss: 0.5834\nEpoch 23/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 90ms/step - accuracy: 0.8277 - loss: 0.5847\nEpoch 24/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.6373 - loss: 0.5946\nEpoch 25/25\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 99ms/step - accuracy: 0.6782 - loss: 0.5940\nFound 11 images belonging to 1 classes.\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - accuracy: 0.6364 - loss: 0.7229\nTest accuracy: 0.6363636255264282\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1714739321.892119     116 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"}]}]}